{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5b3d2f-2f42-4920-9eb7-9c7bcdadacbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: speechrecognition in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (3.14.5)\n",
      "Requirement already satisfied: ollama in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (0.6.1)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (2.99)\n",
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp313-cp313-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from speechrecognition) (4.14.1)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from speechrecognition) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from speechrecognition) (0.2.2)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from ollama) (2.9.2)\n",
      "Requirement already satisfied: comtypes in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from pyttsx3) (1.4.13)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from pyttsx3) (310)\n",
      "Requirement already satisfied: anyio in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=2.9->ollama) (2.23.4)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\odath\\appdata\\roaming\\python\\python313\\site-packages (from standard-aifc->speechrecognition) (3.13.0)\n",
      "Downloading PyAudio-0.2.14-cp313-cp313-win_amd64.whl (173 kB)\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install speechrecognition ollama pyttsx3 pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1917e37-be25-4c9c-ad64-f429234735b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import ollama\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8c54e-9eb8-46bc-86af-e8a518fe32bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen():\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Listening... (Speak now)\")\n",
    "            \n",
    "            recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "\n",
    "            \n",
    "            audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)\n",
    "            print(\"Processing...\")\n",
    "\n",
    "        \n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"You said: {text}\")\n",
    "        return text\n",
    "\n",
    "    except sr.WaitTimeoutError:\n",
    "        print(\"No speech detected (timeout).\")\n",
    "        return None\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I didn't catch that.\")\n",
    "        return None\n",
    "    except sr.RequestError:\n",
    "        print(\"Speech recognition service unavailable.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in listen(): {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399fa34-7e9c-4270-aa8f-39049c735b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def think(text: str):\n",
    "    if not text:\n",
    "        return None\n",
    "\n",
    "    print(\"Thinking...\")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model=\"llama3\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text,\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        response_text = response[\"message\"][\"content\"]\n",
    "        print(f\"AI: {response_text}\")\n",
    "        return response_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in think(): {e}\")\n",
    "        return \"Sorry, something went wrong while thinking.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc5285-ea39-45d3-aaf3-fc9570a1aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text: str):\n",
    "    if not text:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "\n",
    "        \n",
    "        voices = engine.getProperty(\"voices\")\n",
    "        if voices:\n",
    "            \n",
    "            engine.setProperty(\"voice\", voices[0].id)\n",
    "\n",
    "        engine.setProperty(\"rate\", 175) \n",
    "\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in speak(): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c86516-89a2-40e2-9553-83882c554b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Voice Assistant Started ---\n",
      "Listening... (Speak now)\n",
      "No speech detected (timeout).\n",
      "Listening... (Speak now)\n",
      "Processing...\n",
      "You said: I What is the use of an AI\n",
      "Thinking...\n",
      "AI: What a great question!\n",
      "\n",
      "Artificial Intelligence (AI) has numerous uses across various industries and aspects of our lives. Here are some examples:\n",
      "\n",
      "1. **Automation**: AI can automate repetitive, mundane tasks, freeing humans to focus on more complex and creative work.\n",
      "2. **Customer Service**: Chatbots and virtual assistants powered by AI can provide 24/7 customer support, answering queries, and resolving issues efficiently.\n",
      "3. **Healthcare**:\n",
      "\t* Diagnostic tools: AI helps doctors diagnose diseases earlier and more accurately, such as detecting cancer from medical images.\n",
      "\t* Personalized medicine: AI analyzes patient data to create tailored treatment plans.\n",
      "4. **Financial Services**: AI-powered systems can:\n",
      "\t* Analyze financial data to predict market trends and make informed investment decisions.\n",
      "\t* Detect fraud and prevent cyber attacks on financial institutions.\n",
      "5. **Manufacturing**:\n",
      "\t* Predictive maintenance: AI detects equipment malfunctions before they occur, reducing downtime and improving efficiency.\n",
      "\t* Supply chain management: AI optimizes logistics and inventory management.\n",
      "6. **Transportation**: AI is used in:\n",
      "\t* Self-driving cars: AI enables autonomous vehicles to navigate roads safely and efficiently.\n",
      "\t* Traffic management: AI helps optimize traffic light timing and route planning for smoother traffic flow.\n",
      "7. **Education**:\n",
      "\t* Adaptive learning: AI adjusts the difficulty level of educational content based on individual student performance.\n",
      "\t* Virtual teaching assistants: AI-powered tools assist teachers in grading, feedback, and lesson planning.\n",
      "8. **Marketing**: AI-driven marketing strategies include:\n",
      "\t* Personalized advertising: AI creates targeted ads based on user behavior and preferences.\n",
      "\t* Sentiment analysis: AI analyzes customer sentiment to improve customer service and loyalty programs.\n",
      "9. **Security**: AI-powered systems can:\n",
      "\t* Detect and prevent cyber attacks by analyzing network traffic and behavior.\n",
      "\t* Enhance physical security by monitoring surveillance footage and detecting suspicious activity.\n",
      "10. **Research**: AI accelerates scientific discovery in fields like:\n",
      "\t* Materials science: AI optimizes material properties for new applications.\n",
      "\t* Climate modeling: AI helps predict climate change impacts and develop mitigation strategies.\n",
      "\n",
      "These are just a few examples of the many ways AI is used today. As AI technology continues to evolve, we can expect even more innovative applications across various industries!\n",
      "Listening... (Speak now)\n",
      "No speech detected (timeout).\n",
      "Listening... (Speak now)\n",
      "No speech detected (timeout).\n",
      "Listening... (Speak now)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     23\u001b[39m         speak(ai_response)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m speak(\u001b[33m\"\u001b[39m\u001b[33mHello, I am ready. You can start speaking.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# 1. Listen\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     user_input = \u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Skip if nothing heard\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_input:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mlisten\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m     recognizer.adjust_for_ambient_noise(source, duration=\u001b[32m0.5\u001b[39m)\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Listen for audio input\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     audio = \u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Recognize speech using Google's free API\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\speech_recognition\\__init__.py:461\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    459\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\speech_recognition\\__init__.py:493\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time > timeout:\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[33m\"\u001b[39m\u001b[33mlistening timed out while waiting for phrase to start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    495\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\speech_recognition\\__init__.py:192\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pyaudio\\__init__.py:570\u001b[39m, in \u001b[36mPyAudio.Stream.read\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_input:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot input stream\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"--- Voice Assistant Started ---\")\n",
    "    speak(\"Hello, I am ready. You can start speaking.\")\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        user_input = listen()\n",
    "\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        if user_input.lower().strip() in [\"exit\", \"stop\", \"quit\"]:\n",
    "            speak(\"Goodbye!\")\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        \n",
    "        ai_response = think(user_input)\n",
    "\n",
    "        \n",
    "        speak(ai_response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2492465-b64d-4426-9f26-70d927e5a110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
